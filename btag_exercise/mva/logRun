
Processing TMVAAnalysis.C...
<HEADER> DataSetInfo              : [dataset] : Added class "Signal"
                         : Add Tree efficiencyTree of type Signal with 9288 events
<HEADER> DataSetInfo              : [dataset] : Added class "Background"
                         : Add Tree efficiencyTree of type Background with 240000 events
<HEADER> Factory                  : Booking method: BDT
                         : 
<HEADER> DataSetFactory           : [dataset] : Number of events in input trees
                         : Dataset[dataset] :     Signal     requirement: "l1Pt_1 > 0 && l1Pt_2 > 0 && l1Mass > 0 && l1Pt_1 < 511 && l1Pt_2 < 511"
                         : Dataset[dataset] :     Signal          -- number of events passed: 4836   / sum of weights: 4836 
                         : Dataset[dataset] :     Signal          -- efficiency             : 0.520672
                         : Dataset[dataset] :     Background requirement: "l1Pt_1 > 0 && l1Pt_2 > 0 && l1Mass > 0 && l1Pt_1 < 511 && l1Pt_2 < 511"
                         : Dataset[dataset] :     Background      -- number of events passed: 3377   / sum of weights: 3377 
                         : Dataset[dataset] :     Background      -- efficiency             : 0.0140708
                         : Dataset[dataset] :  you have opted for interpreting the requested number of training/testing events
                         :  to be the number of events AFTER your preselection cuts
                         : 
                         : Dataset[dataset] :  you have opted for interpreting the requested number of training/testing events
                         :  to be the number of events AFTER your preselection cuts
                         : 
                         : Dataset[dataset] : Weight renormalisation mode: "EqualNumEvents": renormalises all event classes ...
                         : Dataset[dataset] :  such that the effective (weighted) number of events in each class is the same 
                         : Dataset[dataset] :  (and equals the number of events (entries) given for class=0 )
                         : Dataset[dataset] : ... i.e. such that Sum[i=1..N_j]{w_i} = N_classA, j=classA, classB, ...
                         : Dataset[dataset] : ... (note that N_j is the sum of TRAINING events
                         : Dataset[dataset] :  ..... Testing events are not renormalised nor included in the renormalisation factor!)
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 2418
                         : Signal     -- testing events             : 2418
                         : Signal     -- training and testing events: 4836
                         : Dataset[dataset] : Signal     -- due to the preselection a scaling factor has been applied to the numbers of requested events: 0.520672
                         : Background -- training events            : 1688
                         : Background -- testing events             : 1688
                         : Background -- training and testing events: 3376
                         : Dataset[dataset] : Background -- due to the preselection a scaling factor has been applied to the numbers of requested events: 0.0140708
                         : 
<HEADER> DataSetInfo              : Correlation matrix (Signal):
                         : ---------------------------------------------------------
                         :              l1Pt_1  l1Pt_2 l1DeltaEta l1DeltaPhi  l1Mass
                         :     l1Pt_1:  +1.000  +0.690     +0.014     -0.024  +0.357
                         :     l1Pt_2:  +0.690  +1.000     -0.012     -0.015  +0.372
                         : l1DeltaEta:  +0.014  -0.012     +1.000     +0.028  -0.019
                         : l1DeltaPhi:  -0.024  -0.015     +0.028     +1.000  -0.008
                         :     l1Mass:  +0.357  +0.372     -0.019     -0.008  +1.000
                         : ---------------------------------------------------------
<HEADER> DataSetInfo              : Correlation matrix (Background):
                         : ---------------------------------------------------------
                         :              l1Pt_1  l1Pt_2 l1DeltaEta l1DeltaPhi  l1Mass
                         :     l1Pt_1:  +1.000  +0.571     -0.044     +0.004  +0.248
                         :     l1Pt_2:  +0.571  +1.000     -0.027     -0.011  +0.300
                         : l1DeltaEta:  -0.044  -0.027     +1.000     +0.033  +0.007
                         : l1DeltaPhi:  +0.004  -0.011     +0.033     +1.000  -0.029
                         :     l1Mass:  +0.248  +0.300     +0.007     -0.029  +1.000
                         : ---------------------------------------------------------
<HEADER> DataSetFactory           : [dataset] :  
                         : 
<HEADER> Factory                  : Booking method: MLP
                         : 
<HEADER> MLP                      : [dataset] : Create Transformation "N" with events from all classes.
                         : 
<HEADER>                          : Transformation, Variable selection : 
                         : Input : variable 'l1Pt_1' <---> Output : variable 'l1Pt_1'
                         : Input : variable 'l1Pt_2' <---> Output : variable 'l1Pt_2'
                         : Input : variable 'l1DeltaEta' <---> Output : variable 'l1DeltaEta'
                         : Input : variable 'l1DeltaPhi' <---> Output : variable 'l1DeltaPhi'
                         : Input : variable 'l1Mass' <---> Output : variable 'l1Mass'
<HEADER> MLP                      : Building Network. 
                         : Initializing weights
<HEADER> Factory                  : Train all methods
<HEADER> Factory                  : [dataset] : Create Transformation "I" with events from all classes.
                         : 
<HEADER>                          : Transformation, Variable selection : 
                         : Input : variable 'l1Pt_1' <---> Output : variable 'l1Pt_1'
                         : Input : variable 'l1Pt_2' <---> Output : variable 'l1Pt_2'
                         : Input : variable 'l1DeltaEta' <---> Output : variable 'l1DeltaEta'
                         : Input : variable 'l1DeltaPhi' <---> Output : variable 'l1DeltaPhi'
                         : Input : variable 'l1Mass' <---> Output : variable 'l1Mass'
<HEADER> TFHandler_Factory        :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:      56.261      47.607   [      5.5000      481.00 ]
                         :     l1Pt_2:      39.852      32.491   [      5.5000      447.50 ]
                         : l1DeltaEta:    0.088252      3.0574   [     -8.4150      8.4050 ]
                         : l1DeltaPhi:    0.073492      2.8890   [     -6.0168      6.0168 ]
                         :     l1Mass:      254.83      367.75   [  7.7601e-07      4395.7 ]
                         : ---------------------------------------------------------------------
                         : Ranking input variables (method unspecific)...
<HEADER> IdTransformation         : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Separation
                         : -----------------------------------
                         :    1 : l1Pt_1     : 3.771e-01
                         :    2 : l1Pt_2     : 2.386e-01
                         :    3 : l1Mass     : 1.577e-01
                         :    4 : l1DeltaPhi : 4.897e-02
                         :    5 : l1DeltaEta : 4.722e-02
                         : -----------------------------------
<HEADER> Factory                  : Train method: BDT for Classification
                         : 
<HEADER> BDT                      : #events: (reweighted) sig: 2053 bkg: 2053
                         : #events: (unweighted) sig: 2418 bkg: 1688
                         : Training 800 Decision Trees ... patience please
                         : Elapsed time for training with 4106 events: 1.49 sec         
<HEADER> BDT                      : [dataset] : Evaluation of BDT on training sample (4106 events)
                         : Elapsed time for evaluation of 4106 events: 0.359 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_BDT.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_BDT.class.C
                         : TMVA_output.root:/dataset/Method_BDT/BDT
<HEADER> Factory                  : Training finished
                         : 
<HEADER> Factory                  : Train method: MLP for Classification
                         : 
                         : 
                         : ================================================================
                         : H e l p   f o r   M V A   m e t h o d   [ MLP ] :
                         : 
                         : --- Short description:
                         : 
                         : The MLP artificial neural network (ANN) is a traditional feed-
                         : forward multilayer perceptron implementation. The MLP has a user-
                         : defined hidden layer architecture, while the number of input (output)
                         : nodes is determined by the input variables (output classes, i.e., 
                         : signal and one background). 
                         : 
                         : --- Performance optimisation:
                         : 
                         : Neural networks are stable and performing for a large variety of 
                         : linear and non-linear classification problems. However, in contrast
                         : to (e.g.) boosted decision trees, the user is advised to reduce the 
                         : number of input variables that have only little discrimination power. 
                         : 
                         : In the tests we have carried out so far, the MLP and ROOT networks
                         : (TMlpANN, interfaced via TMVA) performed equally well, with however
                         : a clear speed advantage for the MLP. The Clermont-Ferrand neural 
                         : net (CFMlpANN) exhibited worse classification performance in these
                         : tests, which is partly due to the slow convergence of its training
                         : (at least 10k training cycles are required to achieve approximately
                         : competitive results).
                         : 
                         : Overtraining: only the TMlpANN performs an explicit separation of the
                         : full training sample into independent training and validation samples.
                         : We have found that in most high-energy physics applications the 
                         : available degrees of freedom (training events) are sufficient to 
                         : constrain the weights of the relatively simple architectures required
                         : to achieve good performance. Hence no overtraining should occur, and 
                         : the use of validation samples would only reduce the available training
                         : information. However, if the performance on the training sample is 
                         : found to be significantly better than the one found with the inde-
                         : pendent test sample, caution is needed. The results for these samples 
                         : are printed to standard output at the end of each training job.
                         : 
                         : --- Performance tuning via configuration options:
                         : 
                         : The hidden layer architecture for all ANNs is defined by the option
                         : "HiddenLayers=N+1,N,...", where here the first hidden layer has N+1
                         : neurons and the second N neurons (and so on), and where N is the number  
                         : of input variables. Excessive numbers of hidden layers should be avoided,
                         : in favour of more neurons in the first hidden layer.
                         : 
                         : The number of cycles should be above 500. As said, if the number of
                         : adjustable weights is small compared to the training sample size,
                         : using a large number of training samples should not lead to overtraining.
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : ================================================================
                         : 
<HEADER> TFHandler_MLP            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:    -0.78649     0.20024   [     -1.0000      1.0000 ]
                         :     l1Pt_2:    -0.84456     0.14702   [     -1.0000      1.0000 ]
                         : l1DeltaEta:    0.011088     0.36354   [     -1.0000      1.0000 ]
                         : l1DeltaPhi:    0.012215     0.48015   [     -1.0000      1.0000 ]
                         :     l1Mass:    -0.88406     0.16732   [     -1.0000      1.0000 ]
                         : ---------------------------------------------------------------------
                         : Training Network
                         : 
                         : Elapsed time for training with 4106 events: 12.4 sec         
<HEADER> MLP                      : [dataset] : Evaluation of MLP on training sample (4106 events)
                         : Elapsed time for evaluation of 4106 events: 0.00874 sec       
                         : Creating xml weight file: dataset/weights/TMVAClassification_MLP.weights.xml
                         : Creating standalone class: dataset/weights/TMVAClassification_MLP.class.C
                         : Write special histos to file: TMVA_output.root:/dataset/Method_MLP/MLP
<HEADER> Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
<HEADER> BDT                      : Ranking result (top variable is best ranked)
                         : --------------------------------------------
                         : Rank : Variable   : Variable Importance
                         : --------------------------------------------
                         :    1 : l1Pt_1     : 2.310e-01
                         :    2 : l1DeltaEta : 2.014e-01
                         :    3 : l1DeltaPhi : 1.946e-01
                         :    4 : l1Pt_2     : 1.914e-01
                         :    5 : l1Mass     : 1.816e-01
                         : --------------------------------------------
<HEADER> MLP                      : Ranking result (top variable is best ranked)
                         : -----------------------------------
                         : Rank : Variable   : Importance
                         : -----------------------------------
                         :    1 : l1Pt_1     : 7.469e+01
                         :    2 : l1Pt_2     : 4.525e+01
                         :    3 : l1Mass     : 2.594e+01
                         :    4 : l1DeltaEta : 4.200e+00
                         :    5 : l1DeltaPhi : 2.296e+00
                         : -----------------------------------
<HEADER> Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
<HEADER> MLP                      : Building Network. 
                         : Initializing weights
<HEADER> Factory                  : Test all methods
<HEADER> Factory                  : Test method: BDT for Classification performance
                         : 
<HEADER> BDT                      : [dataset] : Evaluation of BDT on testing sample (4106 events)
                         : Elapsed time for evaluation of 4106 events: 0.276 sec       
<HEADER> Factory                  : Test method: MLP for Classification performance
                         : 
<HEADER> MLP                      : [dataset] : Evaluation of MLP on testing sample (4106 events)
                         : Elapsed time for evaluation of 4106 events: 0.00856 sec       
<HEADER> Factory                  : Evaluate all methods
<HEADER> Factory                  : Evaluate classifier: BDT
                         : 
<HEADER> BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
<HEADER> TFHandler_BDT            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:      59.723      49.178   [      5.5000      501.50 ]
                         :     l1Pt_2:      42.134      34.310   [      5.5000      425.50 ]
                         : l1DeltaEta:   0.0032155      3.0335   [     -8.4100      9.3000 ]
                         : l1DeltaPhi:   -0.017988      2.9140   [     -6.1912      5.8424 ]
                         :     l1Mass:      258.07      359.00   [      6.4743      4739.8 ]
                         : ---------------------------------------------------------------------
<HEADER> Factory                  : Evaluate classifier: MLP
                         : 
<HEADER> TFHandler_MLP            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:    -0.77193     0.20685   [     -1.0000      1.0862 ]
                         :     l1Pt_2:    -0.83424     0.15525   [     -1.0000     0.90045 ]
                         : l1DeltaEta:  0.00097688     0.36070   [    -0.99941      1.1064 ]
                         : l1DeltaPhi:  -0.0029896     0.48431   [     -1.0290     0.97101 ]
                         :     l1Mass:    -0.88258     0.16334   [    -0.99705      1.1566 ]
                         : ---------------------------------------------------------------------
<HEADER> MLP                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
<HEADER> TFHandler_MLP            :   Variable          Mean          RMS   [        Min          Max ]
                         : ---------------------------------------------------------------------
                         :     l1Pt_1:    -0.77193     0.20685   [     -1.0000      1.0862 ]
                         :     l1Pt_2:    -0.83424     0.15525   [     -1.0000     0.90045 ]
                         : l1DeltaEta:  0.00097688     0.36070   [    -0.99941      1.1064 ]
                         : l1DeltaPhi:  -0.0029896     0.48431   [     -1.0290     0.97101 ]
                         :     l1Mass:    -0.88258     0.16334   [    -0.99705      1.1566 ]
                         : ---------------------------------------------------------------------
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : dataset       BDT            : 0.864
                         : dataset       MLP            : 0.863
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : dataset              BDT            : 0.192 (0.429)       0.591 (0.719)      0.861 (0.885)
                         : dataset              MLP            : 0.191 (0.189)       0.584 (0.549)      0.847 (0.853)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
<HEADER> Dataset:dataset          : Created tree 'TestTree' with 4106 events
                         : 
<HEADER> Dataset:dataset          : Created tree 'TrainTree' with 4106 events
                         : 
<HEADER> Factory                  : Thank you for using TMVA!
                         : For citation information, please visit: http://tmva.sf.net/citeTMVA.html
